{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import plot_roc_curve, roc_curve, auc, roc_auc_score\n",
    "from scipy import interp\n",
    "from sklearn.metrics import confusion_matrix, average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, KFold, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.initializers import HeNormal, Constant\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pprint import pprint\n",
    "\n",
    "df = pd.read_csv(r\"Data.csv\", sep=\";\")\n",
    "y = df[\"Target\"]\n",
    "X = df.iloc[:, 1:-1]\n",
    "# print(X)\n",
    "\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# Final test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, test_size=0.30, random_state=1)\n",
    "X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_train, \n",
    "                                                    y_train, test_size=0.30, random_state=1)\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "X_train_val = X_train_val.astype(np.float32)\n",
    "X_test_val = X_test_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "y_test_val = y_test_val.astype(np.float32)\n",
    "\n",
    "y_train = np.array(y_train).reshape(-1,1)\n",
    "y_test = np.array(y_test).reshape(-1,1)\n",
    "y_train_val = np.array(y_train_val).reshape(-1,1)\n",
    "y_test_val = np.array(y_test_val).reshape(-1,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters = {'batch_size': 128, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'n_hidden': 3}\n",
    "\n",
    "def build_model(num_features: int, \n",
    "                learning_rate: float,\n",
    "                n_hidden: int,\n",
    "                batch_size: int,\n",
    "                dropout_rate: float) -> Model:\n",
    "    \n",
    "    init_w = tf.keras.initializers.HeNormal()\n",
    "    init_b = tf.keras.initializers.Constant(value=0.0)\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    \n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1_000, kernel_initializer=init_w, bias_initializer=init_b, input_shape=(num_features,)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Activation(\"elu\"))\n",
    "    for i in range(0, n_hidden):\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(units=1_000-i*250, kernel_initializer=init_w, bias_initializer=init_b))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Activation(\"elu\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=num_targets, kernel_initializer=init_w, bias_initializer=init_b))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Activation(\"sigmoid\"))    \n",
    "    # model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )    \n",
    "    \n",
    "    return model\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_targets = 1 \n",
    "epochs = 50\n",
    "\n",
    "for idx, comb in enumerate(grid):\n",
    "    param_grid = {\n",
    "        'n_hidden': [3],\n",
    "        'learning_rate': [0.001],\n",
    "        'dropout_rate': [0.0],\n",
    "        'batch_size' : [128]\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        \"best_score\": -np.inf,\n",
    "        \"best_params\": {},\n",
    "        \"val_scores\": [],\n",
    "        \"params\": []\n",
    "    }\n",
    "\n",
    "    grid = ParameterGrid(param_grid)\n",
    "    print(f\"Parameter combinations in total: {len(grid)}\")\n",
    "    pprint(param_grid) \n",
    "\n",
    "    model = build_model(\n",
    "        num_features, \n",
    "        **comb)\n",
    "\n",
    "    ANN = model.fit(\n",
    "        X_train_val,\n",
    "        y_train_val,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "    )\n",
    "    #       berechnet die Accuracy\n",
    "    scores = model.evaluate(\n",
    "        X_train_val,\n",
    "        y_train_val,\n",
    "        verbose=1\n",
    "        )\n",
    "\n",
    "    results[\"val_scores\"].append(scores)\n",
    "    results[\"params\"].append(comb)\n",
    "    print(f\"Accuracy = {scores}\")\n",
    "\n",
    "ypred = model.predict(X_test_val) \n",
    "ypred = tf.math.round(ypred)\n",
    "\n",
    "print(classification_report(y_test_val, ypred, digits=3))\n",
    "print(confusion_matrix(y_test_val,ypred))\n",
    "print(f\"Average precision score {average_precision_score(y_test_val, ypred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter initialization\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_targets = 1 \n",
    "\n",
    "param_grid = {\n",
    "    'n_hidden': [3],\n",
    "    'learning_rate': [0.001],\n",
    "    'dropout_rate': [0],\n",
    "    'batch_size': [128]\n",
    "}\n",
    "\n",
    "results = {\n",
    "    \"best_score\": -np.inf,\n",
    "    \"best_params\": {},\n",
    "    \"val_scores\": [],\n",
    "    \"params\": []\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(param_grid)\n",
    "print(f\"Parameter combinations in total: {len(grid)}\")\n",
    "pprint(param_grid) \n",
    "\n",
    "for idx, comb in enumerate(grid):\n",
    "    model = build_model(\n",
    "        num_features, \n",
    "        **comb)\n",
    "\n",
    "    ANN = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "    )\n",
    "#       berechnet die Accuracy\n",
    "    scores = model.evaluate(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        verbose=1\n",
    "        )\n",
    "\n",
    "    results[\"val_scores\"].append(scores)\n",
    "    results[\"params\"].append(comb)\n",
    "    print(f\"Accuracy = {scores}\")\n",
    "\n",
    "ypred = model.predict(X_test) \n",
    "ypred = tf.math.round(ypred)\n",
    "\n",
    "print(classification_report(y_test, ypred, digits=3))\n",
    "print(confusion_matrix(y_test,ypred))\n",
    "print(f\"Average precision score {average_precision_score(y_test, ypred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROC Curve \n",
    "\n",
    "   \n",
    "from sklearn.metrics import plot_roc_curve, roc_curve, auc, roc_auc_score\n",
    "init_w = tf.keras.initializers.HeNormal()\n",
    "init_b = tf.keras.initializers.Constant(value=0.0)\n",
    "num_features = X_train.shape[1]\n",
    "num_targets = 1 \n",
    "learning_rate = 0.001\n",
    "n_hidden = 3\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "dropout_rate = 0.0\n",
    "no_splits = 5\n",
    "\n",
    "cv = StratifiedKFold(n_splits=no_splits)\n",
    "results = np.zeros_like(y_train, dtype=np.float32)\n",
    "\n",
    "\n",
    "prbs = []\n",
    "tprs = []\n",
    "fprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "    \n",
    "j = 0\n",
    "for train_val_idx, test_val_idx in cv.split(X_train_val, y_train_val):\n",
    "    while j < no_splits: \n",
    "        print(\">>\")\n",
    "        print(f\"Fold = {j}\")\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=1_000, kernel_initializer=init_w, bias_initializer=init_b, \n",
    "                        input_shape=(num_features,)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Activation(\"elu\"))\n",
    "        for i in range(0, n_hidden):\n",
    "            model.add(Dropout(dropout_rate))\n",
    "            model.add(Dense(units=1_000-i*250, kernel_initializer=init_w, bias_initializer=init_b))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "            model.add(Activation(\"elu\"))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(units=num_targets, kernel_initializer=init_w, bias_initializer=init_b))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Activation(\"sigmoid\"))    \n",
    "        model.summary()\n",
    "\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(learning_rate=learning_rate),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X[train_idx,:], y.iloc[train_idx], epochs=epochs, \n",
    "                  batch_size=batch_size, verbose=1)\n",
    "\n",
    "        probas_ = model.predict(X[test_idx,:])\n",
    "        prbs.append(probas_)\n",
    "        fpr, tpr, thresholds = roc_curve(y.iloc[test_idx], probas_[ :])\n",
    "\n",
    "        interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        auc_ = auc(fpr, tpr)\n",
    "        aucs.append(auc_)\n",
    "\n",
    "        plt.plot(fpr, tpr,\n",
    "            label=r'ROC fold %i (AUC = %0.3f )' % (j, auc_),\n",
    "            lw=1, alpha=.3)        \n",
    "        j += 1\n",
    "\n",
    "# Average the predictions        \n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc =np.std(aucs)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "        label=r'Mean ROC (AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc, std_auc),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"e) Receiver operating characteristic DNN\")\n",
    "ax.set_xlabel('False Positive Rate (Positive label: 1)')\n",
    "ax.set_ylabel('True Positive Rate (Positive label: 1)')\n",
    "\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.savefig(\"ann.pdf\", dpi=600,transparent=True)\n",
    "plt.savefig(\"ann.jpg\", dpi=600,transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y-Randomisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "accur = []\n",
    "for i in range(1,100):\n",
    "    y_rand = shuffle(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y_rand, test_size=0.30, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    ypred = model.predict(X_test)\n",
    "    ypred = tf.round(ypred)\n",
    "    accur.append(average_precision_score(y_test, ypred))\n",
    "    print(classification_report(y_test,ypred,digits=3,zero_division=1 ))\n",
    "    print(confusion_matrix(y_test,ypred))\n",
    "print(f\"Mean f1 score = {np.mean(accur):.3f}, std {np.std(accur):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
